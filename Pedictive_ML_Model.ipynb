{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFtZqyepq/6KgqNULDcaek",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreya7931/Data-Science-Challenge/blob/main/Pedictive_ML_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('/content/p1_movie_metadata (1).csv')\n",
        "\n",
        "# Feature engineering\n",
        "# Create interaction features\n",
        "data['budget_duration_interaction'] = data['budget'] * data['duration']\n",
        "\n",
        "# Genre Frequency\n",
        "genre_frequency = data['genres'].str.get_dummies(sep='|').mean()\n",
        "data['genre_frequency'] = data['genres'].apply(lambda x: sum([genre_frequency[g] for g in x.split('|')]) / len(x.split('|')))\n",
        "\n",
        "# Director's Hit Rate\n",
        "director_hit_rate = data.groupby('director_name')['imdb_score'].mean().fillna(0)\n",
        "data['director_hit_rate'] = data['director_name'].map(director_hit_rate)\n",
        "\n",
        "# Lead Actor's Fame\n",
        "lead_actor_fame = (data['actor_1_name'].map(data.groupby('actor_1_name')['actor_1_facebook_likes'].mean()) +\n",
        "                   data['actor_2_name'].map(data.groupby('actor_2_name')['actor_2_facebook_likes'].mean())) / 2\n",
        "data['lead_actor_fame'] = lead_actor_fame.fillna(0)\n",
        "\n",
        "# Budget-to-Gross Ratio\n",
        "data['budget_to_gross_ratio'] = data['budget'] / data['gross']\n",
        "\n",
        "# Handling missing values\n",
        "numerical_columns = data.select_dtypes(include=['number']).columns\n",
        "categorical_columns = data.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "data[numerical_columns] = data[numerical_columns].fillna(data[numerical_columns].median())\n",
        "data[categorical_columns] = data[categorical_columns].fillna(data[categorical_columns].mode().iloc[0])\n",
        "\n",
        "# Separate features and target variables\n",
        "X = data.drop(['title_year', 'genres', 'movie_title', 'movie_imdb_link'], axis=1)\n",
        "y_release_year = data['title_year']\n",
        "y_genres = data['genres'].str.get_dummies(sep='|')\n",
        "\n",
        "# Get the most probable genre for each movie\n",
        "y_train_genres_labels = y_genres.idxmax(axis=1)\n",
        "\n",
        "# Split data into train and test sets for release year prediction\n",
        "X_train_release_year, X_test_release_year, y_train_release_year, y_test_release_year = train_test_split(\n",
        "    X, y_release_year, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split data into train and test sets for genre prediction\n",
        "X_train_genres, X_test_genres, y_train_genres_labels, y_test_genres_labels = train_test_split(\n",
        "    X, y_train_genres_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define numerical and categorical features\n",
        "numerical_features = ['num_critic_for_reviews', 'duration', 'director_facebook_likes',\n",
        "                      'actor_1_facebook_likes', 'gross', 'num_voted_users',\n",
        "                      'cast_total_facebook_likes', 'facenumber_in_poster',\n",
        "                      'num_user_for_reviews', 'budget', 'actor_2_facebook_likes',\n",
        "                      'imdb_score', 'aspect_ratio', 'movie_facebook_likes',\n",
        "                      'budget_duration_interaction', 'genre_frequency',\n",
        "                      'director_hit_rate', 'lead_actor_fame', 'budget_to_gross_ratio']\n",
        "categorical_features = ['color', 'language', 'country', 'content_rating']\n",
        "\n",
        "# Preprocessing pipeline for numerical features\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Preprocessing pipeline for categorical features\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numerical_transformer, numerical_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "# Preprocess the data for release year prediction\n",
        "X_train_release_year_preprocessed = preprocessor.fit_transform(X_train_release_year)\n",
        "X_test_release_year_preprocessed = preprocessor.transform(X_test_release_year)\n",
        "\n",
        "# Define XGBoost regressor for release year prediction\n",
        "xgb_regressor = GradientBoostingRegressor()\n",
        "\n",
        "# Fit XGBoost regressor for release year prediction\n",
        "xgb_regressor.fit(X_train_release_year_preprocessed, y_train_release_year)\n",
        "\n",
        "# Predict release year\n",
        "release_year_predictions = xgb_regressor.predict(X_test_release_year_preprocessed)\n",
        "release_year_mae = mean_absolute_error(y_test_release_year, release_year_predictions)\n",
        "print(\"Mean Absolute Error (Release Year Prediction) - XGBoost Regressor:\", release_year_mae)\n",
        "\n",
        "# Preprocess the data for genre prediction\n",
        "X_train_genres_preprocessed = preprocessor.fit_transform(X_train_genres)\n",
        "X_test_genres_preprocessed = preprocessor.transform(X_test_genres)\n",
        "\n",
        "# Define XGBoost classifier for genre prediction\n",
        "xgb_classifier = GradientBoostingClassifier()\n",
        "\n",
        "# Fit XGBoost classifier for genre prediction\n",
        "xgb_classifier.fit(X_train_genres_preprocessed, y_train_genres_labels)\n",
        "\n",
        "# Predict genres\n",
        "genres_predictions = xgb_classifier.predict(X_test_genres_preprocessed)\n",
        "\n",
        "# Evaluate accuracy\n",
        "genres_accuracy = accuracy_score(y_test_genres_labels, genres_predictions)\n",
        "print(\"Accuracy (Genres Prediction) - XGBoost Classifier:\", genres_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKMNgyZZIF5K",
        "outputId": "da9eb360-84da-47c6-ec12-78d2efea7768"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (Release Year Prediction) - XGBoost Regressor: 4.685647034153494\n",
            "Accuracy (Genres Prediction) - XGBoost Classifier: 0.7819623389494549\n"
          ]
        }
      ]
    }
  ]
}